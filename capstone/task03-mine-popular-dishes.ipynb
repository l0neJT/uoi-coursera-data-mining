{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loganjtravis@gmail.com (Logan Travis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "# Imports; captures errors to supress warnings about changing\n",
    "# import syntax\n",
    "\n",
    "from lxml import html\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import wikipediaapi\n",
    "\n",
    "\n",
    "# import random\n",
    "# import gensim.models as models, \\\n",
    "#        gensim.matutils as matutils, \\\n",
    "#        gensim.corpora as corpora\n",
    "# import matplotlib.pyplot as plot\n",
    "# import nltk\n",
    "\n",
    "# import pandas as pd\n",
    "# import scipy as sp\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.feature_extraction.text import CountVectorizer, \\\n",
    "#                                             TfidfTransformer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity, \\\n",
    "#                                      euclidean_distances, \\\n",
    "#                                      paired_cosine_distances\n",
    "# from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for repeatability\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set matplotlib to inline to preserve images in PDF\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "From course page [Week 3 > Task 3 Information > Task 3 Overview](https://www.coursera.org/learn/data-mining-project/supplement/7Ro4J/task-3-overview):\n",
    "\n",
    "> The goal of this task is to mine the data set to discover the common/popular dishes of a particular cuisine. Typically when you go to try a new cuisine, you don’t know beforehand the types of dishes that are available for that cuisine. For this task, we would like to identify the dishes that are available for a cuisine by building a dish recognizer.\n",
    "> \n",
    "> **Instructions**\n",
    ">\n",
    "> Before you begin, make sure you have downloaded the data set and any additional tools you wish to use, as described on the [Data Set and Toolkit Acquisition](https://www.coursera.org/learn/data-mining-project/supplement/Ij7rp/data-set-and-toolkit-acquisition) page.\n",
    "> \n",
    "> Some questions to consider when building the dish recognizer are the following:\n",
    "> \n",
    "> 1. What types of dishes are present in the reviews for a cuisine?\n",
    "> 2. Are there any surprising dishes in the list you annotated?\n",
    "> 3. What types of dishes were you able to find?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean List of Mexican Dishes\n",
    "\n",
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths to data source, work in process (\"WIP\"), and output\n",
    "PATH_SOURCE = \"source/\"\n",
    "PATH_WIP = \"wip/\"\n",
    "PATH_OUTPUT = \"output/\"\n",
    "\n",
    "# Set file paths\n",
    "PATH_SOURCE_MEXICAN_LABELS = PATH_SOURCE + \"labels/Mexican.label\"\n",
    "PATH_SOURCE_MEXICAN_TO_DEL = PATH_SOURCE + \"labels/Mexican_TO_DEL.label\"\n",
    "PATH_SOURCE_MEXICAN_TO_FLIP = PATH_SOURCE + \"labels/Mexican_TO_FLIP.label\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Provided List\n",
    "\n",
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read initial dish list for Mexican cuisine\n",
    "dfMexDishes = pd.read_csv(PATH_SOURCE_MEXICAN_LABELS, sep=\"\\t\", names=[\"dish\", \"include\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make `dish` column the index\n",
    "dfMexDishes.set_index(\"dish\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `include` column to boolean data type\n",
    "dfMexDishes.include = dfMexDishes.include.astype(np.bool_,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dish list has shape (597, 1).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>include</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dish</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fried egg</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in n out</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triple sec</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mexican food</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service stars</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               include\n",
       "dish                  \n",
       "fried egg         True\n",
       "in n out          True\n",
       "triple sec        True\n",
       "mexican food      True\n",
       "service stars     True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print dish list shape and head\n",
    "print(\"Dish list has shape {}.\".format(dfMexDishes.shape))\n",
    "dfMexDishes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Non-Dishes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dishes to drop for Mexican cuisine\n",
    "wip = pd.read_csv(PATH_SOURCE_MEXICAN_TO_DEL, sep=\"\\t\", names=[\"dish\", \"include\"], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed dishes to drop from dish list\n",
    "dfMexDishes.drop(wip.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dish list has shape (412, 1).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>include</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dish</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beef tongue</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refried beans</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carne asada</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rice pudding</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tomato soup</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               include\n",
       "dish                  \n",
       "beef tongue       True\n",
       "refried beans     True\n",
       "carne asada       True\n",
       "rice pudding      True\n",
       "tomato soup       True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print dish list shape and head\n",
    "print(\"Dish list has shape {}.\".format(dfMexDishes.shape))\n",
    "dfMexDishes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flip Indicator for False-Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dishes flip drop for Mexican cuisine\n",
    "wip = pd.read_csv(PATH_SOURCE_MEXICAN_TO_FLIP, sep=\"\\t\", names=[\"dish\", \"include\"], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed dishes to drop from dish list\n",
    "dfMexDishes.loc[wip.index, \"include\"] = ~dfMexDishes.loc[wip.index, \"include\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Dishes from Wikipedia\n",
    "\n",
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Wikipedia page \"List of Mexican dishes\" and parse as HTML\n",
    "wp = wikipediaapi.Wikipedia('en', extract_format=wikipediaapi.ExtractFormat.HTML)\n",
    "wpMexDishesPage = wp.page(\"List_of_Mexican_dishes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function to pretty-print secitons\n",
    "def printSections(sections, level=0):\n",
    "    \"\"\"Pretty-print sections from `wikipediaapi` page.\"\"\"\n",
    "    for i, s in enumerate(sections):\n",
    "        print(\"{}{:d}. {}\".format(\" \" * 4 * level, i, s.title))\n",
    "        printSections(s.sections, level + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Antojitos\n",
      "1. Cheese  dishes\n",
      "2. Egg dishes\n",
      "3. Meat dishes\n",
      "    0. Beef dishes\n",
      "    1. Goat dishes\n",
      "    2. Pork dishes\n",
      "    3. Poultry dishes\n",
      "    4. Other meat and protein dishes\n",
      "4. Moles, sauces, dips and spreads\n",
      "5. Rice dishes\n",
      "6. Seafood dishes\n",
      "7. Soups and stews\n",
      "8. Vegetable dishes\n",
      "9. Desserts and sweets\n",
      "10. Beverages\n",
      "    0. Non-alcoholic\n",
      "    1. Alcoholic\n",
      "11. See also\n",
      "12. References\n",
      "13. External links\n"
     ]
    }
   ],
   "source": [
    "# Examine sections\n",
    "printSections(wpMexDishesPage.sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>Street food in Mexico, called <i>antojitos</i> is prepared by street vendors and at small traditional markets in Mexico. Most of them include corn as an ingredient.\\n</p>\\n<ul><li>Aguachile</li>\\n<li>Bolillos (salty bread)</li>\\n<li>Burrito</li>\\n<li>Camote (Mexican sweet potato)</li>\\n<li>Cemitas sandwiches</li>\\n<li>Chalupa</li>\\n<li>Chapulines and escamoles</li>\\n<li>Charales, small fish, basically a type of smelt</li>\\n<li>Chicharrón</li></ul>\\n<ul><li>Chilaquiles</li>\\n<li>Chimichangas (Tex-Mex mostly)</li>\\n<li>Choriqueso</li>\\n<li>Chorizo</li></ul>\\n<ul><li>Cochinita pibil</li>\\n<li>Cocido</li>\\n<li>Cóctel de camarón and other seafood cocktails</li>\\n<li>Corunda</li>\\n<li>Curtido</li>\\n<li>Elote</li>\\n<li>Enchilada (red or green)</li>\\n<li>Enfrijoladas</li>\\n<li>Ensalada de fruta (fruit salad)</li>\\n<li>Entomatadas</li>\\n<li>Fajitas</li>\\n<li>Filete de pescado</li></ul>\\n<ul><li>Flautas</li>\\n<li>Frijoles charros</li>\\n<li>Fritada</li>\\n<li>Gorditas</li>\\n<li>Gringas</li>\\n<li>Huauzontles</li>\\n<li>Huaraches</li>\\n<li>Jicama</li>\\n<li>Jocoque</li>\\n<li>Lengua</li>\\n<li>Lentil soup (lentil beans)</li>\\n<li>Longaniza</li>\\n<li>Machaca</li>\\n<li>Mancha manteles</li>\\n<li>Memela</li></ul>\\n\\n<ul><li>Menudo</li>\\n<li>Mixiotes</li>\\n<li>Mole de olla</li>\\n<li>Mole poblano</li>\\n<li>Molletes</li>\\n<li>Molotes</li>\\n<li>Moronga</li>\\n<li>Nachos</li>\\n<li>Pambazos</li>\\n<li>Panucho</li>\\n<li>Papadzules</li>\\n<li>Parilladas</li>\\n<li>Pastel azteca</li>\\n<li>Pejelagarto</li>\\n<li>Picadillo</li>\\n<li>Quesadillas</li>\\n<li>Queso</li>\\n<li>Rajas con crema</li>\\n<li>Romeritos</li>\\n<li>Salbutes</li>\\n<li>Salsa</li>\\n<li>Sincronizadas</li></ul>\\n<ul><li>Sopes\\n<ul><li>Sopa de albondiga (meatball soup)</li></ul></li></ul>\\n<ul><li>Tacos</li>\\n<li>Taco al pastor</li>\\n<li>Tamales</li>\\n<li>Taquitos</li>\\n<li>Tlacoyos</li>\\n<li>Tlayudas</li>\\n<li>Tortas (sandwiches) - see also small omelettes similar to egg foo yung patties, see also romeritos</li>\\n<li>Tortillas</li>\\n<li>Tostadas</li>\\n<li>Totopo</li>\\n<li>Tripas</li>\\n<li>Venado (venison), particularly in the Yucatan</li>\\n<li>Yuca (cassava)</li></ul>'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get text from an example section\n",
    "wpMexDishesPage.sections[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function to get list of dishes from section text\n",
    "def getDishesFromText(sectionText, removeTextAfter=\"[,-]\", wordLimit=3):\n",
    "    \"\"\"Return a list of dish names from section text.\"\"\"\n",
    "    tree = None\n",
    "    \n",
    "    # Create an `lxml` element tree from HTML.\n",
    "    tree = html.fromstring(sectionText)\n",
    "    \n",
    "    # Get dishes from <li> element text\n",
    "    dishes = tree.xpath(\"//li/text()\")\n",
    "    \n",
    "    # Remove parentheticals\n",
    "    dishes = [re.sub(r\"\\(.*?\\)\", \"\", t) for t in dishes]\n",
    "    \n",
    "    # Remove text after passed characters\n",
    "    dishes = [re.sub(\"(?<={}).*$\".format(removeTextAfter), \"\", t) for t in dishes]\n",
    "    \n",
    "    # Trim to word limit\n",
    "    dishes = [\" \".join(re.split(r\"\\W+\", t)[:wordLimit]).strip() for t in dishes]\n",
    "    \n",
    "    # Return list of dishes\n",
    "    return set(dishes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function to recursively get dishes from all\n",
    "# sections\n",
    "def getDishesFromSection(section):\n",
    "    \"\"\"Recusively print list of sections from `wikipediaapi` page.\"\"\"\n",
    "#     print(section.title)\n",
    "    if(len(section.sections) == 0):\n",
    "        return getDishesFromText(section.text)\n",
    "    else:\n",
    "        dishes = set()\n",
    "        for s in section.sections:\n",
    "            dishes.update(getDishesFromSection(s))\n",
    "        return dishes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Mexican dishes from Wikipedia page \"List of Mexican dishes\"\n",
    "wpMexDishes = set()\n",
    "for section in wpMexDishesPage.sections[:11]:\n",
    "    wpMexDishes.update(getDishesFromSection(section))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty items and known bad elements then\n",
    "# format for inclusion in common phrases\n",
    "wpMexDishes = [(d.lower(), 1) for d in wpMexDishes \\\n",
    "               if d not in [\"is of\", \"or\", \"\", \"as a\", \"where these\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dataframe and merge\n",
    "dfMexDishesFromWP = pd.DataFrame(wpMexDishes, columns=[\"dish\", \"include\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make `dish` column the index\n",
    "dfMexDishesFromWP.set_index(\"dish\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `include` column to boolean data type\n",
    "dfMexDishesFromWP.include = dfMexDishesFromWP.include.astype(np.bool_,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge original dish list and Wikipedia dish list then\n",
    "# fill missing values as False\n",
    "dfMexDishes = dfMexDishes.merge(dfMexDishesFromWP, how=\"outer\", \\\n",
    "                                left_index=True, right_index=True, \\\n",
    "                                suffixes=[\"_initial\", \"_from_wp\"])\n",
    "dfMexDishes.fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine final inclusion from initial list or from Wikipedia\n",
    "dfMexDishes[\"include_combined\"] = dfMexDishes.include_initial | dfMexDishes.include_from_wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 243 dishes to incldue and 391 common phrase to exclude as dishes.\n"
     ]
    }
   ],
   "source": [
    "# List dishes to include\n",
    "print(\"Found {:,} dishes to incldue and {:,} common phrase to exclude as dishes.\".format(\\\n",
    "        sum(dfMexDishes.include_combined), \\\n",
    "        sum(~dfMexDishes.include_combined)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Yelp Review Data Set\n",
    "\n",
    "I cleaned the Yelp review data and extraced cuisines from the business data set in separate notebooks. Loading saved data to shorten this report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PATH_SOURCE_YELP_REVIEWS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-fe62b84f85e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read saved data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdfYelpReviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_SOURCE_YELP_REVIEWS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdfYelpRestToCuis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_SOURCE_YELP_REST_TO_CUISINES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcuisines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_SOURCE_YELP_CUISINES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cuisine\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PATH_SOURCE_YELP_REVIEWS' is not defined"
     ]
    }
   ],
   "source": [
    "# Read saved data\n",
    "dfYelpReviews = pd.read_pickle(PATH_SOURCE_YELP_REVIEWS)\n",
    "dfYelpRestToCuis = pd.read_pickle(PATH_SOURCE_YELP_REST_TO_CUISINES)\n",
    "cuisines = pd.read_csv(PATH_SOURCE_YELP_CUISINES, names=[\"cuisine\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfYelpReviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-c0e8e31c8939>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Join (inner) reviews to restaurants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdfYelpReviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfYelpReviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfYelpRestToCuis\u001b[0m\u001b[0;34m,\u001b[0m                                    \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"business_id\"\u001b[0m\u001b[0;34m,\u001b[0m                                    \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inner\"\u001b[0m\u001b[0;34m,\u001b[0m                                    \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"_business\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dfYelpReviews' is not defined"
     ]
    }
   ],
   "source": [
    "# Join (inner) reviews to restaurants\n",
    "dfYelpReviews = dfYelpReviews.join(dfYelpRestToCuis, \\\n",
    "                                   on=\"business_id\", \\\n",
    "                                   how=\"inner\", \\\n",
    "                                   rsuffix=\"_business\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine Cuisine Similarity via Term Frequencies\n",
    "\n",
    "I calculate the term frequencies across cuisines both with and without inverse-document frequency as an initial comparison. These methods take comparatively less time and also pre-compute data necessary for more advanced similarity comparisons like my seeded-LDA topic approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Parameters\n",
    "\n",
    "I found the settings below worked well when extracting topics for the week one assignment:\n",
    "\n",
    "* Limit maximum terms to 10,000. This is an extreme upper limit. The SciKit Learn `TfidfVectorizer` class ([link to documentation](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)) never yielded more than 5,000 terms based on my other parameters.\n",
    "* Exclude terms appearing in more than 50% of documents. These add little value for differntiating topics.\n",
    "* Exclude terms appearing in less than 0.1% of documents. I tested many settings for this parameter ranging down to 2 documents and up to 10% of all documents. The Yelp reviews include numerious limited-use terms (e.g., people and place names) and I found it difficult to interpret the topics with too many present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set token limit\n",
    "MAX_FEATURES = 10000\n",
    "\n",
    "# Set document frequency ceiling; topic analysis will ignore\n",
    "# words found in more documents\n",
    "MAX_DF = 0.5\n",
    "\n",
    "# Set document frequency floor; topic analysis will ignore\n",
    "# words found in fewer document\n",
    "MIN_DF = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer:\n",
    "    def __init__(self):\n",
    "        \"\"\"String tokenizer utilizing lemmatizing and stemming.\"\"\"\n",
    "        self.wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    def __call__(self, document):\n",
    "        \"\"\"Return tokens from a string.\"\"\"\n",
    "        return [self.wnl.lemmatize(token) for \\\n",
    "                        token in nltk.word_tokenize(document)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excessive Data Set Size\n",
    "\n",
    "I worked on a 50% sample of the Yelp reviews for restaurants. The full data set proved too large for my machine's memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working dataframe to a 50% sample of the full data set;\n",
    "# too large otherwise\n",
    "df = dfYelpReviews.sample(frac=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index to simple integer; simplifies document selection\n",
    "# in TF matrix\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF vectorizer \n",
    "tf = CountVectorizer(max_features=MAX_FEATURES, max_df=MAX_DF, \\\n",
    "                     min_df=MIN_DF, stop_words=\"english\", \\\n",
    "                     tokenizer=MyTokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Calculate term frequencies\n",
    "docTerms = tf.fit_transform(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print token matrix shape\n",
    "print(\"Found {0[1]:,} tokens in {0[0]:,} documents\".format(docTerms.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuisine TF Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort cuisines alphabetically\n",
    "cuisines = cuisines.sort_values(by=\"cuisine\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Sum term frequencies across documents for each cuisine\n",
    "cuisineTerms = sp.sparse.coo_matrix((0, docTerms.shape[1]))\n",
    "for c in cuisines.cuisine:\n",
    "    idxs = df[df.categories.apply(lambda cats: c in cats)].index\n",
    "    cuisineTerms = sp.sparse.vstack([cuisineTerms, docTerms[idxs, ].sum(axis=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to CSR sparse matrix to facility row-wise operations\n",
    "cuisineTerms = cuisineTerms.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize term frequencies by cuisine for initial graph\n",
    "cuisineTermsL2Norm = normalize(cuisineTerms, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define graphing function for reusability\n",
    "def graphSimilarity(matrix, labels, title, display_labels=True, colors=None, \\\n",
    "                    matrix_under=None, alpha_over=0.2):\n",
    "    \"\"\"Graph a similarity matrix.\"\"\"\n",
    "    fig, ax = plot.subplots()\n",
    "    fig.set_size_inches(8, 8)\n",
    "    \n",
    "    # Generate matrix image with or without underlay\n",
    "    cmap = colors if not None else plot.cm.get_cmap(\"viridis\")\n",
    "    if matrix_under is None:\n",
    "        cax = ax.matshow(matrix, cmap=cmap)\n",
    "    else:\n",
    "        cmap_over = plot.get_cmap(\"binary_r\")\n",
    "        cax_under = ax.matshow(matrix_under, cmap=cmap, vmin=0, vmax=1)\n",
    "        cax = ax.matshow(matrix, cmap=cmap_over, alpha=alpha_over)\n",
    "        \n",
    "    \n",
    "    # Configure axes\n",
    "    ax.xaxis.tick_top()\n",
    "    if display_labels:\n",
    "        plot.xticks(range(matrix.shape[0]), labels, rotation=90)\n",
    "        plot.yticks(range(matrix.shape[0]), labels)\n",
    "    \n",
    "    # Add title (as x-axis label) and color bar\n",
    "    ax.set_xlabel(title)\n",
    "    fig.colorbar(cax)\n",
    "    \n",
    "    # Return plot\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cosine similarity for all cuisine TFs\n",
    "matrix = cosine_similarity(cuisineTermsL2Norm)\n",
    "labels = cuisines.cuisine\n",
    "_, _ = graphSimilarity(matrix, labels, \\\n",
    "                       \"Cuisine TF (L2 Norm) Cosine Similarity\", \\\n",
    "                       display_labels=False)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While quick, calculating cosine similarity from intra-topic normalized term frequencies yields poor results. Many cuisines appear unrelated to all others as indicated by the dark bands (i.e., cosine similarity near zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample cuisines for detailed view\n",
    "SAMPLE_20 = sorted(random.sample(range(cuisines.shape[0]), 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cosine similarity for random 20 cuisine TFs\n",
    "matrix = cosine_similarity(cuisineTermsL2Norm[SAMPLE_20, :])\n",
    "labels = cuisines.iloc[SAMPLE_20, ].cuisine\n",
    "_, _ = graphSimilarity(matrix, labels, \\\n",
    "                       \"Cuisine TF (L2 Norm) Cosine Similarity - Random Subset\", \\\n",
    "                       display_labels=True)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zooming in on a sample of cuisines shows some expected similarities: Delis to Bagels and Asian Fusion to Sushi Bars. Still, most cuisines appear unrelated to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuisine TF-IDF Cosine Similarity\n",
    "\n",
    "Applying IDF weighting should improve the cuisine comparison. Note that \"document\" in IDF does not mean the individual reviews. It instead means the topics. I essentially create an imaginary document summing all the terms seen in reviews for a given topic.\n",
    "\n",
    "I considered calculating TF-IDF against the reviews. That would yield better per-term weighting. However, I do not know how to consolidate the review-driven TF-IDF results across topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF transformer from counts\n",
    "tfToTfidf = TfidfTransformer(norm=\"l2\", use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate TF-IDF for topics\n",
    "cuisineTermsIDF = tfToTfidf.fit_transform(cuisineTerms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cosine similarity for all cuisines TF-IDF\n",
    "matrix = cosine_similarity(cuisineTermsIDF)\n",
    "labels = cuisines.cuisine\n",
    "_, _ = graphSimilarity(matrix, labels, \\\n",
    "                       \"Cuisine TF-IDF Cosine Similarity\",\n",
    "                       display_labels=False)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immediately we see the IDF produces a better similarity spread. Many cuisines relate closely to one another - as expected in the real world - while some retain their distinctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cosine similarity for random 20 cuisine TF-IDFs\n",
    "matrix = cosine_similarity(cuisineTermsIDF[SAMPLE_20, :])\n",
    "labels = cuisines.iloc[SAMPLE_20, ].cuisine\n",
    "_, _ = graphSimilarity(matrix, labels, \\\n",
    "                       \"Cuisine TF-IDF Cosine Similarity - Random Subset\", \\\n",
    "                       display_labels=True)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same sampled cuisines reveal new similarities after applying IDF: Asian Fusion to Caribbean and Ethiopian to Tapas/Small Plates. The IDF also highlights the not-quite-cuisines like Bagels, Donuts, Famers Market, and Patisserie/Cake Shop.\n",
    "\n",
    "Not all results makes intuitive sense. Delis, a not-quite-cuisine, displays moderate similarity with most cuisines. So too does Wineries. Their reviews may exhibit enough common terms to explain the similarities. As an example, many restaurants sell alcohol so might relate to Wineries regardless of cuisine.\n",
    "\n",
    "I still think I can improve the cuisine map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuisine TF-IDF Euclidian Distance\n",
    "\n",
    "I perform a quick sanity check by comparing TF-IDF accross cuisines using Euclidean distance. It produces similar results to cosine similarity (with color scale reversed). That makes sense since all the TF-IDF vectors point into the same sector (i.e., all positive values) and have similar magnitudes due to normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get revers viridis color map\n",
    "cmap_viridis_r = plot.get_cmap(\"viridis_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot euclidian distance (reverse color map) for all \n",
    "# cuisine TF-IDF\n",
    "matrix = euclidean_distances(cuisineTermsIDF)\n",
    "labels = cuisines.cuisine\n",
    "_, _ = graphSimilarity(matrix, labels, \\\n",
    "                       \"Cuisine TF-IDF Euclidean Distance\", \\\n",
    "                       display_labels=False, colors=cmap_viridis_r)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot euclidian distance (reverse color map) for random \n",
    "# 20 cuisine TF-IDFs\n",
    "matrix = euclidean_distances(cuisineTermsIDF[SAMPLE_20, :])\n",
    "labels = cuisines.iloc[SAMPLE_20, ].cuisine\n",
    "_, _ = graphSimilarity(matrix, labels, \\\n",
    "                       \"Cuisine TF-IDF Euclidean Distance - Random Subset\", \\\n",
    "                       display_labels=True, colors=cmap_viridis_r)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine Cuisine Similarity via LDA\n",
    "\n",
    "Improving the cuisine map requires improving the text-based representation of each cuisine. LDA offers one potential method: Attempt to discover topics that match cuisines. I say \"attempt\" because LDA is an unsuperived algorithm; I cannot provide it the cuisines as ground truths.\n",
    "\n",
    "I research extensions of LDA with supervised or \"guided\" learning. See [Google Scholar Articles Related to Labeled LDA](https://scholar.google.com/scholar?um=1&ie=UTF-8&lr&q=related:632kE3NGZGxZRM:scholar.google.com/). Unfortunately, I found myself time constrained so choose instead to seed the regular LDA with cuisine TFs as a-priori probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of topics\n",
    "NUM_TOPICS = cuisines.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate TF-IDF for terms\n",
    "docTermsIDF = tfToTfidf.fit_transform(docTerms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert GenSim corpus from token matrix\n",
    "corpus = matutils.Sparse2Corpus(docTermsIDF, documents_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GenSim dictionary for documents; Note: Passes the\n",
    "# vectorizer tokens as a single \"document\".\n",
    "dictionary = corpora.Dictionary([tf.get_feature_names()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%capture --no-stdout\n",
    "\n",
    "# Find topic using LDA with a-priori from cuisine TF\n",
    "lda = models.ldamulticore.LdaMulticore(corpus, \\\n",
    "                                       num_topics=NUM_TOPICS,\n",
    "                                       id2word=dict(dictionary.items()), \\\n",
    "                                       eta=cuisineTerms.todense().tolist()) # Memory intensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get topic distribution for each cuisine\n",
    "rows, cols, vals = [], [], []\n",
    "cuisineTerms = cuisineTerms.tocsr()\n",
    "for i in range(cuisines.shape[0]):\n",
    "    row = cuisineTerms.getrow(0)\n",
    "    bow = list(zip(row.indices, row.data))\n",
    "    for c, v in lda.get_document_topics(bow, minimum_probability=0):\n",
    "        rows.append(i)\n",
    "        cols.append(c)\n",
    "        vals.append(v)\n",
    "cuisineTopics = sp.sparse.csr_matrix((vals, (rows, cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cosine similarity for all cuisine LDA topics\n",
    "matrix = cosine_similarity(cuisineTopics)\n",
    "labels = cuisines.cuisine\n",
    "_, _ = graphSimilarity(matrix, labels, \\\n",
    "                       \"Cuisine LDA Topic Cosine Similarity\", \\\n",
    "                       display_labels=False)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the scale of the colorbar. It reaches a maximum of just 0.0001 suggesting the seeded-LDA produced topics nearly matching cuisines (i.e. nearly orthogonal). I think the overall effect improves on TF-IDF similarity but only slightly. Notabely, the seeded-LDA approach removes many of the dark bands finding similarities for cuisines that previously appeared completely dissimilar from all others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cosine similarity for random 20 cuisine \n",
    "# LDA topics\n",
    "matrix = cosine_similarity(cuisineTopics[SAMPLE_20, :])\n",
    "labels = cuisines.iloc[SAMPLE_20, ].cuisine\n",
    "_, _ = graphSimilarity(matrix, labels, \\\n",
    "                       \"Cuisine LDA Topic Cosine Similarity - Random Subset\", \\\n",
    "                       display_labels=True)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closer inspection of the sample cuisines shows a \"flattened\" similarity matrix. Strong dis/similarities appear like Asian Fusion to Tapas/Small Plates (strongly similar) and Delis to Singaporean (strongly dissimilar). Still, the flattened matrix would benefit from better defining such dis/similarities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Similar Cuisines\n",
    "\n",
    "I improve the seeded-LDA comparison of cuisines by clustering them and ordering them around those clusters. This took a lot of experimentation. I tried as few as two clusters and as many as 16. I tried varies overlays on the similarity matrix to highlight clusters. I also tried both cosine similarity and euclidean distance again when ordering cuisines within each cluster.\n",
    "\n",
    "Four clusters and cosine similarity yieleded the best cuisine map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Cuisine Topics with K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train K-Means clustering instance\n",
    "cuisineTopicClustersKM = KMeans(n_clusters=4, random_state=42).fit(cuisineTopics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster labels and score to cuisines dataframe\n",
    "cuisines[\"cluster_km\"] = cuisineTopicClustersKM.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distance to cluster centroid\n",
    "getCentroidDistance = lambda r: paired_cosine_distances(\\\n",
    "        cuisineTopics.getrow(r.name).todense(), \\\n",
    "        cuisineTopicClustersKM.cluster_centers_[r[\"cluster_km\"]].reshape(1, NUM_TOPICS) \\\n",
    ")[0]\n",
    "cuisines[\"centroid_dist_km\"] = cuisines.apply(getCentroidDistance, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sorted index by cluster ID and distance to\n",
    "# cluster centriod\n",
    "sortedIdx = cuisines.sort_values(by=[\"cluster_km\", \"centroid_dist_km\"]).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get categorical color map for overlay\n",
    "cmap_tab10 = plot.get_cmap(\"tab10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cosine similarity for all clustered cuisine \n",
    "# LDA topics\n",
    "matrix = cosine_similarity(cuisineTopics[sortedIdx])\n",
    "labels = cuisines.cuisine[sortedIdx]\n",
    "clusterCols = np.array([cuisines.cluster_km[sortedIdx].values / 5, ] * cuisines.shape[0])\n",
    "_, _ = graphSimilarity(matrix, labels, \\\n",
    "                       \"Clustered Cuisine LDA Topic Cosine Similarity\", \\\n",
    "                       display_labels=False, colors=cmap_tab10, \\\n",
    "                       matrix_under=clusterCols, alpha_over=0.8)\n",
    "\n",
    "# Show plot\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each vertical band of color represents a cluster of similar cuisines. The resulting squares along the diagonal highlight the most similar cuisines pushing disimilarities toward the edges of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort sample\n",
    "SORTED_SAMPLE_20 = [i for i in sortedIdx if i in SAMPLE_20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cosine similarity for random 20 clustered cuisine\n",
    "# LDA topics\n",
    "matrix = cosine_similarity(cuisineTopics[SORTED_SAMPLE_20, :])\n",
    "labels = cuisines.cuisine[SORTED_SAMPLE_20]\n",
    "clusterCols = np.array([cuisines.cluster_km[SORTED_SAMPLE_20].values / 5, ] * 20)\n",
    "_, ax = graphSimilarity(matrix, labels, \\\n",
    "                        \"Clustered Cuisine LDA Topic Cosine Similarity - Random Subset\", \\\n",
    "                        display_labels=True, colors=cmap_tab10, \\\n",
    "                        matrix_under=clusterCols, alpha_over=0.8)\n",
    "\n",
    "# Show plot\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zooming in shows the value of clustering. Cuisines with strong similarities in the real world appear with each other. This makes comparison between them visually easier. Clustering also reveals a weakness in using review text to represent cuisines: It includes significant non-cuisine information. The {Asian Fusion, Dive Bars, Tapas/Small Plates, Brewies} cluster more likely reflects 'trendy dining' than it does cuisine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
